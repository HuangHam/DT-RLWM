#Basic functions used across models
from scipy.optimize import minimize#for the gradient descent function
import scipy.stats as st #for correlation coef
import matplotlib
import matplotlib.pyplot as plt # for plotting. Make sure use ggplot style for consistency
import math as m
import numpy as np # for numeric calculations
import pandas as pd # for python data 
import seaborn as sns #for genc and recover
import functools as ft
from itertools import combinations #for combinations
'''
Computational Auxilary functions
'''
def softmax(V,beta):
    '''
    p = softmax(V) returns the softmax policy 
    (probability distribution of picking an action)
    
    V = [v1,v2, ...,vn] is an n dimensional real vector representating 
    the value of n different options
    
    beta is the inverse temperature parameter, a non-negative scalar
    
    p =[p1,p2, ..., pn] is the probability vector of selecting actions 
    1-n under softmax policy with values V
    '''
    # rescuing high betas at the cost of efficiency
    p = np.array([1 / np.sum(np.exp(beta * (V - V[a]))) for a in range(len(V))])
    
    # error checking
    if (np.sum(p)<0) or (np.sum(p)>1.000001) or (np.any(np.isnan(p)) or ( not np.allclose(np.sum(p),1))):
        print(p)
        print(beta)
        print(V)
        raise ValueError('p is not a probability')
    return(p)
def sigTrans(beta):
    return (2/(1+np.exp(-beta)))-1
#pandas numpy conversion
def get_AIC(bestllh, NParam):
    return 2 * bestllh + 2 * NParam
def get_BIC(bestllh, NParam, nSample):
    return 2 * bestllh + np.log(nSample) * NParam
def optimize(fname, bounds, Data, niter, toplot=False, ):
    #  bestparameters,bestllh = optimize(fname,bounds, Data,niter,toplot) runs
    #  the minimize function niter times on the function fname, with constraints
    #  bounds to find parameters that best fit the data Data. It returns the
    #  best likelihood and best fit parameters over the niter iterations.
    #  ## fname is the python function to optimize. fname
    #  should take as first argument a 1 by n vector of parameters.
    #  Note the bounds are set up differently than they are in Matlab,
    #  And should come as a list of [min,max] pairs. (ie. [[min,max],[min,max], ...])
    #
    #  ## Data is the data set to be fit by likelihood function fname.
    #  ## niter is the number of starting points for the optimization
    #  ## toplot is an optional argument; if plot~=0, this function will plot the
    #  best likelihood as a function of starting point iterations.
    #  ## best parameters is the 1*n vector of parameters found to minimize the
    #  negative log likelihood over the data.
    #  bestllh is the log likelihood value for the best parameters.
    outcomes = np.full([niter, len(bounds) + 1], np.nan)
    optimcurve = np.full(niter, np.nan)
    for i in range(niter):
        #print(i)
        # random starting point based on maximum bounds
        params0 = np.array([bound[1] * np.random.rand() for bound in bounds])

        # compute the function value at the starting point
        llh0 = fname(params0, Data)

        # run the optimizer with constraints
        result = minimize(fun=fname, x0=params0, args=(Data), bounds=bounds)
        x = result.x
        bestllh = fname(x, Data)
        outcomes[i, :] = [bestllh] + [xi for xi in x]
        optimcurve[i] = min(outcomes[:(i + 1), 0])
    # find the global minimum out of all outcomes
    i = np.argwhere(outcomes[:, 0] == np.min(outcomes[:, 0]))
    bestparameters = outcomes[i[0], 1:].flatten()
    # bestllh = -1 * outcomes[i[0], 0].flatten()[0]
    bestllh = outcomes[i[0], 0].flatten()[0]
    # plot the best llh found by the optimizer as a function of iteration number.
    if toplot:
        plt.figure()
        plt.plot(range(niter), np.round(optimcurve, 6), 'o-')
        plt.xlabel('iteration')
        plt.ylabel('best minimum')
        plt.title(str(nblocks) + ' blocks')
    return (bestparameters, bestllh)
'''
Fitting Procedural Auxilary functions
'''
def np2pd(Data, colnames):
    # takes in a np Data generated by an agent for the DT-RLWM task
    # and turn it into a pd dataframe
    return pd.DataFrame(Data, columns=colnames)
def pd2np(Data):
    # takes in any dp Data
    # output np array
    return Data.to_numpy()
def stimSeq(Data):
    def stimSeq(stim):
        elem = {k: int(i + 1) for i, k in enumerate(np.unique(stim))}
        return list(map(elem.get, stim))
    Nsub = np.unique(Data['subject'])
    data = Data.sort_values(by=['subject', 'image_set'])
    Seq = np.array([], dtype=int)
    for n in Nsub:
        Sub = Data[Data.subject == n]
        s = np.unique(data['image_set'])
        for set in s:
            sub = Sub[Sub.image_set == set]
            stim = list(sub['stimuli'])
            seq = stimSeq(stim)
            Seq = np.append(Seq, seq)
    data['stimSeq'] = Seq
    return data.sort_values(by=['subject', 'block'])
def actBias(Data, na=3):
    def popAct(Action, Cor, CorAct):
        '''
        Take in the action, Cor, and CorAct array from data of a block
        :return: array of popular action of each trial (i.e., most rewarded WRONG action at the present trial)
        '''
        #initialize
        pop, cumRew, cumAct = np.empty(len(Action)), np.zeros(na, dtype=int), np.zeros(na, dtype=int)
        #pop is the final output, cumRew keeps tracks of the cumulative reward each action had,
        # cumAct keeps track of the number of times each action had been chosen
        for i in range(len(Action)):
            a,c,ca = Action[i],Cor[i],int(CorAct[i])
            if np.min(cumAct) == 0: #if one of the action is never adopted
                pop[i] = float('nan') #nan
            else:
                cum = cumRew/cumAct #obtain the rate of reward
                cum[ca-1] = -1
                #make the rate for correct action -1 so that it cannot be picked as the highest rate,
                if len(np.unique(cum)) == na:
                    #if no tie. Because the rate of the correct action is -1, it's the same as no tie between incorrect action
                    pop[i] = np.argmax(cum)+1 #get the action with max rate
                else:
                    pop[i] = float('nan') #if there is a tie, the same
            if not m.isnan(c): #if reward is not nan
                cumRew[int(a)-1] += int(c)
                cumAct[int(a)-1] += 1
        return pop
    Nsub = np.unique(Data['subject'])
    data = Data.sort_values(by=['subject', 'block'])
    Seq = np.array([], dtype=int)
    Seq2 = np.array([], dtype=int)
    for n in Nsub:
        Sub = Data[Data.subject == n]
        Nblock = np.unique(Sub['block'])
        try:
            Nsim = np.unique(Sub['simulation'])
        except:
            for b in Nblock:
                sub = Sub[Sub.block == b]
                action, Cor, CorAct = np.array(sub['action']), np.array(sub['Cor']), np.array(sub['corAct'])
                seq = popAct(action, Cor, CorAct)
                seq2 = np.empty(len(seq))
                for i in range(len(seq)):
                    if m.isnan(seq[i]):
                        seq2[i] = float('nan')
                    else:
                        seq2[i] = seq[i]==action[i]
                Seq, Seq2 = np.append(Seq, seq), np.append(Seq2, seq2)
        else:
            for s in Nsim:
                Sim = Sub[Sub.block == s]
                for b in Nblock:
                    sub = Sim[Sim.block == b]
                    action, Cor, CorAct = np.array(sub['action']), np.array(sub['Cor']), np.array(sub['corAct'])
                    seq = popAct(action, Cor, CorAct)
                    seq2 = np.empty(len(seq))
                    for i in range(len(seq)):
                        if m.isnan(seq[i]):
                            seq2[i] = float('nan')
                        else:
                            seq2[i] = seq[i] == action[i]
                    Seq, Seq2 = np.append(Seq, seq), np.append(Seq2, seq2)
    data['rewAct'] = Seq
    data['isBias'] = Seq2
    return data.sort_values(by=['subject', 'block'])
def opt2IC(LLHFunc, NParam, Data, K, Dis, niter=20, plot=0):
    '''
    :param LLHFunc: Take in LLH function
    :param NParam: number of parameters
    :param Data: the dataset to fit of one subject
    :param K: capacity parameter
    :param plot: whether to plot it (always 0)
    :return: AIC, BIC, Parameter, K for a particular subject
    '''
    bounds = np.tile([0, 1], (NParam-(len(K)>1)-(len(Dis)>1), 1)).tolist()  # set up parameter bound
    best = {}  # dictionary whether keys are bestllh of a capacity, values are the corresponding parameters
    for k in K:  # for each capacity value
        for d in Dis:
            print('  capacity: ' + str((k, d)))
            bestparam, bestllh = optimize(ft.partial(LLHFunc, Kap=k, KapDiscount = d), bounds, Data, niter, plot)  # fit
            best[bestllh] = (bestparam, (k, d))  # store in the dictionary
    llhK = list(best.keys())  # list of best llh for each capacity value
    bestllh = min(llhK)  # find the best(minimum) llh
    bestparam, bestK = best[bestllh][0], best[bestllh][1]  # find corresponding best parameter and capacity value
    AIC, BIC = get_AIC(bestllh, NParam), get_BIC(bestllh, NParam, Data.shape[0])
    return AIC, BIC, bestparam, bestK
def opt2IC_te(te_LLHFunc, te_NParam, NParam, te_Data, endPolicy, niter=20, plot=0):
    '''
    :param LLHFunc: Take in LLH function
    :param NParam: number of parameters
    :param Data: the dataset to fit of one subject
    :param K: capacity parameter
    :param plot: whether to plot it (always 0)
    :return: AIC, BIC, Parameter, K for a particular subject
    '''
    bounds = np.tile([0, 1], (te_NParam, 1)).tolist()  # set up parameter bound
    bestparam, bestllh = optimize(ft.partial(te_LLHFunc, endPolicy = endPolicy), bounds, te_Data, niter, plot)  # fit
    AIC, BIC = get_AIC(bestllh, te_NParam+NParam), get_BIC(bestllh, te_NParam+NParam, te_Data.shape[0])
    return AIC, BIC, bestparam
'''
Recovery Procedural functions
'''
def modRec(Agents, initSample=0, endSample=33,niter=20, plot=0):
    print('now performing model recovery, make sure to caffeinate the computer')
    if endSample>=initSample:
        Samples = range(initSample, endSample)
    else:
        Samples = range(initSample, endSample, -1)
    nsamples = endSample
    AICs, BICs = np.empty((len(Agents), len(Agents), nsamples)), np.empty((len(Agents), len(Agents), nsamples))
    for sa in Samples:
        print('subject ' + str(sa + 1))
        for d in range(len(Agents)):
            agent = Agents[d]
            print('now generating from '+agent.name)
            ModFit = np.load('../ModelFit/ModFit' + agent.name + '.npz', allow_pickle=True)
            Param, Kap = ModFit['Params'], ModFit['Ks']
            AIC, BIC = np.empty(len(Agents)), np.empty(len(Agents))
            Data, e = agent.agent(sa + 1, Param[sa], Kap[sa][0], Kap[sa][1])
            assert len(Param) >= nsamples #make sure nsamples is the number of subject
            for a in range(len(Agents)):
                ag = Agents[a]
                print('recovering using ' + ag.name)
                AIC[a], BIC[a], Param, bestK = opt2IC(ag.LLH, ag.numParam, Data, ag.Krange, ag.KapDiscount, niter=niter, plot=plot)
            # store the relative AIC
            AICs[d, :, sa] = AIC - min(AIC)  # store the relative AIC
            BICs[d, :, sa] = BIC - min(BIC)  # store the relative BIC
        np.savez('Model_Recovery_Sub' + str(sa + 1), AICs=AICs, BICs=BICs)  # save the file as "outfile_name.npy"
    return AICs, BICs
def genRec(agent, niter=33, nstartingpoints=20):
    nParam = len(agent.pname)
    bounds = np.tile([0,1], (nParam,1)).tolist()
    #results of the generate and recover procedure
    genrec, optimcurve = np.full((niter, 2*nParam), np.nan), np.full((niter, nstartingpoints), np.nan)
    ModFit = np.load('../ModelFit/ModFit' + agent.name + '.npz', allow_pickle=True)
    Param, Kap = ModFit['Params'], ModFit['Ks']
    #each line corresponding to one simulated data set.
    assert len(Param) >= niter #make sure niter is the number of subjects
    for i in range(niter):
        print(i)
        param, K = Param[i], Kap[i]#np.random.rand(nParam)
        Data, e = agent.agent(i+1, param, K[0], K[1])
        outcomes = np.full((nstartingpoints, nParam+1), np.nan)
        for s in range(nstartingpoints):
            params0 = np.random.rand(nParam)
            results = minimize(fun=ft.partial(agent.LLH, Kap=K[0], KapDiscount = K[1]), x0=params0, bounds=bounds, args=(Data))
            x = results.x
            bestllh = agent.LLH(x, Data, K[0], K[1])
            outcomes[s] = [bestllh, *x]
            optimcurve[i, s] = np.nanmin(outcomes[:, 0])
        optimcurve[i] -= optimcurve[i, -1]
        bestparameters = outcomes[s, 1:]  # TODO: why not np.max(outcomes[:, 0])?
        genrec[i] = [*param, *bestparameters]
    return genrec, optimcurve, bounds
'''
Plotting functions
'''
#for model recovery (confusion matrix)
def heatmap(data, row_labels, col_labels, xlab, ylab, ax=None,
            cbar_kw={}, cbarlabel="", **kwargs):
    """
    Create a heatmap from a numpy array and two lists of labels.

    Parameters
    ----------
    data
        A 2D numpy array of shape (N, M).
    row_labels
        A list or array of length N with the labels for the rows.
    col_labels
        A list or array of length M with the labels for the columns.
    ax
        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If
        not provided, use current axes or create a new one.  Optional.
    cbar_kw
        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.
    cbarlabel
        The label for the colorbar.  Optional.
    **kwargs
        All other arguments are forwarded to `imshow`.
    """

    if not ax:
        ax = plt.gca()

    # Plot the heatmap
    im = ax.imshow(data, **kwargs)
    # Create colorbar
    cbar = False#ax.figure.colorbar(im, ax=ax, **cbar_kw)
    #cbar.ax.set_ylabel(cbarlabel, rotation=-90, va="bottom")

    # We want to show all ticks...
    ax.set_xticks(np.arange(data.shape[1]))
    ax.set_yticks(np.arange(data.shape[0]))
    # set xbar and ybar label
    ax.yaxis.set_label_position("right")
    ax.set_ylabel(ylab, fontsize = 18,rotation = 270, labelpad=25)
    ax.set_xlabel(xlab, fontsize = 18)
    # ... and label them with the respective list entries.
    ax.set_xticklabels(col_labels, fontsize=11)
    ax.set_yticklabels(row_labels, fontsize=11)

    # Let the horizontal axes labeling appear on top.
    ax.tick_params(top=True, bottom=False,
                   labeltop=True, labelbottom=False)

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=-30, ha="right",
             rotation_mode="anchor")
    plt.setp(ax.get_yticklabels(), rotation=-30, ha="right",
             rotation_mode="anchor")

    # Turn spines off and create white grid.
    for edge, spine in ax.spines.items():
        spine.set_visible(False)

    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)
    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)
    ax.grid(which="minor", color="w", linestyle='-', linewidth=3)
    ax.tick_params(which="minor", bottom=False, left=False)
    ax.axis('tight')
    return im, cbar
def annotate_heatmap(im, data=None, valfmt="{x:.2f}",
                     textcolors=["black", "white"],
                     threshold=None, **textkw):
    """
    A function to annotate a heatmap.

    Parameters
    ----------
    im
        The AxesImage to be labeled.
    data
        Data used to annotate.  If None, the image's data is used.  Optional.
    valfmt
        The format of the annotations inside the heatmap.  This should either
        use the string format method, e.g. "$ {x:.2f}", or be a
        `matplotlib.ticker.Formatter`.  Optional.
    textcolors
        A list or array of two color specifications.  The first is used for
        values below a threshold, the second for those above.  Optional.
    threshold
        Value in data units according to which the colors from textcolors are
        applied.  If None (the default) uses the middle of the colormap as
        separation.  Optional.
    **kwargs
        All other arguments are forwarded to each call to `text` used to create
        the text labels.
    """

    if not isinstance(data, (list, np.ndarray)):
        data = im.get_array()

    # Normalize the threshold to the images color range.
    if threshold is not None:
        threshold = im.norm(threshold)
    else:
        threshold = im.norm(data.max())/2.

    # Set default alignment to center, but allow it to be
    # overwritten by textkw.
    kw = dict(horizontalalignment="center",
              verticalalignment="center")
    kw.update(textkw)

    # Get the formatter in case a string is supplied
    if isinstance(valfmt, str):
        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)

    # Loop over the data and create a `Text` for each "pixel".
    # Change the text's color depending on the data.
    texts = []
    for i in range(data.shape[0]):
        for j in range(data.shape[1]):
            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])
            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)
            texts.append(text)
    return texts
#for parameter recovery
def recPlot(pname, bounds, genrec, numPlot=4):
    nParam = len(pname)
    assert 2 * nParam == np.size(genrec,1)
    pidx = [i for i in range(nParam)]
    parts = [pidx[i * numPlot:(i + 1) * numPlot] for i in range((len(pidx) + numPlot - 1) // numPlot)]
    for part in parts:
        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=0.8)
        n = len(part)
        p = 1
        for idx in part:
            # plot generated against recovered for each parameter
            plt.subplot(m.floor(m.sqrt(n+1)), m.ceil(m.sqrt(n)), p)
            x = genrec[:, idx]
            y = genrec[:, idx + len(genrec[1, :]) // 2]
            sns.regplot(x, y)
            # plot unity
            r = round(st.spearmanr(x, y)[0], 2)
            P = round(st.spearmanr(x, y)[1], 2)
            plt.plot(bounds[idx], linewidth=2)  # orange line is the input bound.Remember beta input is scaled down by 10.
            plt.xlabel('true '+pname[idx], fontsize=15)
            plt.ylabel('recovered', fontsize=15)
            plt.xlim((min(x)-0.1*(max(x)-min(x)), max(x) + 0.1*(max(x)-min(x))))
            plt.ylim((min(y)-0.1*(max(y)-min(y)), max(y)+0.1*(max(y)-min(y))))
            plt.title('\u03C1='+str(r)+',p=' + str(P), fontsize=15)
            p += 1
        plt.show()
def recCorPlot(pname, genrec, numPlot=4):
    nParam = len(pname)
    assert 2 * nParam == np.size(genrec,1)
    nParam = len(pname)
    pidx = [i for i in range(nParam)]
    pairs = [pair for pair in combinations(pidx, 2)]#cartesian product to create correlation pairs
    parts = [pairs[i * numPlot:(i + 1) * numPlot] for i in range((len(pairs) + numPlot - 1) // numPlot)]
    for part in parts:
        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=0.8)  # [source]
        # look for correlations in fit parameters
        # plot generated against recovered for each parameter
        n = len(part)
        p = 1
        for idx in part:
            plt.subplot(m.floor(m.sqrt(n+1)), m.ceil(m.sqrt(n)), p)
            x = genrec[:, nParam+idx[0]]
            y = genrec[:, nParam+idx[1]]
            sns.regplot(x, y)
            r = round(st.pearsonr(x, y)[0], 2)
            plt.xlabel('recovered ' + str(pname[idx[0]]))
            plt.ylabel('recovered ' + str(pname[idx[1]]))
            plt.title('correlations: ' + str(r))
            p += 1
        plt.show()
def recOptPlot(optimcurve):
    mean_optimcurve = np.mean(optimcurve, axis=0)
    se_optimcurve = np.std(optimcurve, axis=0) / np.sqrt(optimcurve.shape[0])
    plt.errorbar(range(len(mean_optimcurve)), np.mean(optimcurve, axis=0), yerr=se_optimcurve)
    plt.xlabel('random starting point number')
    plt.ylabel('optimum llh')
    plt.title('avg bestllh-so-far')
    plt.show()

#for model comparison
def ParamBar(name, pname, Params, Ks=None):
    ParamsMean = np.mean(Params, axis=0)
    ParamSE = st.sem(list(Params))#, nan_policy='omit')  # se
    print(ParamsMean)
    print(ParamSE)
    labels = pname
    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=0.4)
    # width of the bars
    barWidth = 0.3
    # Choose the height of the blue bars
    bars1 = ParamsMean
    # Choose the height of the error bars (bars1)
    yer1 = ParamSE
    # The x position of bars
    r1 = np.arange(len(bars1))
    #r2 = [x for x in r1]
    # Create blue bars
    plt.bar(r1, bars1, width=barWidth, color='blue', edgecolor='black', yerr=yer1,
            capsize=7, label=name +' params')
    # general layout
    plt.xticks([r for r in range(len(bars1))], labels)
    plt.ylabel('Param')
    plt.title('K: '+str(Ks))
    plt.legend()
    plt.show()
def ICBar(AICs, BICs, Mods, barWidth = 0.4, degree = 90):
    # now we have the matrix encoding the absolute ICs for each version,
    # average across participants, finding se, and calculate the relative IC for each model in each version.
    #AICidxBest = np.argmin(np.mean(AICs, axis=0))  # index for the model with lowest average AIC
    #BICidxBest = np.argmin(np.mean(BICs, axis=0))
    AICrel = AICs - np.mean(AICs, axis=1)[:, None] # relative to the first model
    BICrel = BICs - np.mean(BICs, axis=1)[:, None]
    AICrelAvg = np.mean(AICrel, axis=0)  # index for the model with lowest average AIC
    BICrelAvg = np.mean(BICrel, axis=0)
    #ASE = st.sem(AICs)  # se
    #BSE = st.sem(BICs)
    ASErel = st.sem(AICrel)  # se relative
    BSErel = st.sem(BICrel)

    labels = Mods
    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=0.4)
    # Choose the height of the blue bars
    bars1 = list(AICrelAvg)
    # Choose the height of the cyan bars
    bars2 = list(BICrelAvg)
    # Choose the height of the error bars (bars1)
    yer1 = ASErel
    # Choose the height of the error bars (bars2)
    yer2 = BSErel
    # The x position of bars
    r1 = np.arange(len(bars1))
    r2 = [x + barWidth for x in r1]
    # Create blue bars
    plt.bar(r1, bars1, width=barWidth, color='blue', edgecolor='black', yerr=yer1, capsize=7, label='AIC')
    # Create cyan bars
    plt.bar(r2, bars2, width=barWidth, color='orange', edgecolor='black', yerr=yer2, capsize=7, label='BIC')
    # general layout
    plt.xticks([r + 0.5*barWidth for r in range(len(bars1))], labels, fontsize=11)
    plt.xticks(rotation=degree)
    plt.ylabel('\u0394 IC', fontsize=18)
    plt.title(None)
    plt.legend(prop={'size': 18})
    plt.show()